{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training From Pretrained Model Creating Mini Piidgeon models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,AutoConfig, BertTokenizerFast\n",
    "import pytorch_lightning as pl\n",
    "import ast\n",
    "from torchmetrics import Precision, Recall, F1Score, Accuracy\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from typing import Optional, Dict, Any, List\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from torchmetrics.classification import MulticlassPrecision\n",
    "import datetime\n",
    "from safetensors.torch import save_file,load_file\n",
    "\n",
    "\n",
    "class DetailedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Override monitor parameter to use a custom metric\n",
    "        kwargs['monitor'] = 'avg_target_precision'  # Custom metric name\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_metrics = None\n",
    "\n",
    "    def _run_early_stopping_check(self, trainer):\n",
    "        # Calculate average of precision for labels 1 and 2\n",
    "        precision_1 = trainer.callback_metrics.get('val_precision_label_1', torch.tensor(0.0))\n",
    "        precision_2 = trainer.callback_metrics.get('val_precision_label_2', torch.tensor(0.0))\n",
    "        \n",
    "        # Calculate average precision for monitored labels\n",
    "        avg_precision = (precision_1 + precision_2) / 2\n",
    "        \n",
    "        # Update the monitor value in trainer's callback metrics\n",
    "        trainer.callback_metrics['avg_target_precision'] = avg_precision\n",
    "        \n",
    "        stop_training = super()._run_early_stopping_check(trainer)\n",
    "        \n",
    "        if stop_training:\n",
    "            print(\"\\nEarly stopping triggered! Saving best model and metrics...\")\n",
    "            \n",
    "            # Save the model\n",
    "            best_model_path = os.path.join(trainer.checkpoint_callback.dirpath, 'best_model_early_stop')\n",
    "            trainer.lightning_module.model.save_pretrained(best_model_path)\n",
    "            \n",
    "            # Store best metrics\n",
    "            self.best_metrics = {\n",
    "                name: value.item() if hasattr(value, 'item') else value\n",
    "                for name, value in trainer.callback_metrics.items()\n",
    "            }\n",
    "            \n",
    "            # Print detailed metrics\n",
    "            print(\"\\nBest Model Metrics:\")\n",
    "            print(f\"Precision Label 1: {precision_1:.4f}\")\n",
    "            print(f\"Precision Label 2: {precision_2:.4f}\")\n",
    "            print(f\"Average Target Precision: {avg_precision:.4f}\")\n",
    "\n",
    "        return stop_training\n",
    "\n",
    "class LabelMapper:\n",
    "    def __init__(self):\n",
    "        # Start with 'O' as it's always present\n",
    "        self.label_to_id: Dict[str, int] = {'O': 0}\n",
    "        self.id_to_label: Dict[int, str] = {0: 'O'}\n",
    "        self.num_labels: int = 1\n",
    "        \n",
    "    def fit(self, label_sequences: List[List[str]]) -> None:\n",
    "        \"\"\"\n",
    "        Fit the mapper on a list of label sequences, combining B- and I- prefixes.\n",
    "        Args:\n",
    "            label_sequences: List of label sequences, where each sequence is a list of string labels\n",
    "        \"\"\"\n",
    "        # Collect all unique base labels (without B- or I- prefixes)\n",
    "        base_labels = set()\n",
    "        for sequence in label_sequences:\n",
    "            for label in sequence:\n",
    "                if label != 'O':\n",
    "                    # Strip B- or I- prefix and add base label\n",
    "                    base_label = label[2:] if label.startswith(('B-', 'I-')) else label\n",
    "                    base_labels.add(base_label)\n",
    "        \n",
    "        # Sort base labels for consistency\n",
    "        sorted_base_labels = sorted(base_labels)\n",
    "        \n",
    "        # Create mappings for O, B- and I- variants\n",
    "        label_mappings = {'O': 0}  # Start with O\n",
    "        current_idx = 1\n",
    "        \n",
    "        # Create id_to_label mapping that properly preserves B- prefixes\n",
    "        id_to_label_mapping = {0: 'O'}\n",
    "\n",
    "        for base_label in sorted_base_labels:\n",
    "            # Add B- and I- variants with same index\n",
    "            b_label = f'B-{base_label}'\n",
    "            i_label = f'I-{base_label}'\n",
    "            label_mappings[b_label] = current_idx\n",
    "            label_mappings[i_label] = current_idx\n",
    "            # Store the B- variant in id_to_label mapping\n",
    "            id_to_label_mapping[current_idx] = b_label\n",
    "            current_idx += 1\n",
    "            \n",
    "        # Store mappings\n",
    "        self.label_to_id = label_mappings\n",
    "        self.id_to_label = id_to_label_mapping\n",
    "        self.num_labels = current_idx\n",
    "        \n",
    "        # Print mapping information\n",
    "        print(f\"\\nFound {len(base_labels)} unique base labels (excluding O)\")\n",
    "        print(f\"Total number of labels after mapping: {self.num_labels}\")\n",
    "        print(\"\\nLabel mapping:\")\n",
    "        for label, idx in sorted(self.label_to_id.items()):\n",
    "            print(f\"{label}: {idx}\")\n",
    "\n",
    "    def encode(self, labels: List[str]) -> List[int]:\n",
    "        \"\"\"Convert string labels to IDs, maintaining B-/I- sequence.\"\"\"\n",
    "        return [self.label_to_id[label] for label in labels]\n",
    "\n",
    "    def decode(self, ids: List[int]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert IDs back to string labels.\n",
    "        For non-O labels, uses B- prefix for first token of an entity,\n",
    "        I- prefix for subsequent tokens of the same entity.\n",
    "        \"\"\"\n",
    "        decoded_labels = []\n",
    "        prev_id = 0  # O tag\n",
    "        \n",
    "        for id in ids:\n",
    "            if id == 0:\n",
    "                decoded_labels.append('O')\n",
    "                prev_id = 0\n",
    "            else:\n",
    "                base_label = self.id_to_label[id][2:]  # Strip B- prefix from stored label\n",
    "                if id != prev_id:\n",
    "                    # New entity starts\n",
    "                    decoded_labels.append(f'B-{base_label}')\n",
    "                else:\n",
    "                    # Continue existing entity\n",
    "                    decoded_labels.append(f'I-{base_label}')\n",
    "                prev_id = id\n",
    "                \n",
    "        return decoded_labels\n",
    "\n",
    "    def decode_with_bio(self, logits: torch.Tensor, attention_mask: torch.Tensor) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Decode model logits to BIO labels, handling B-/I- prefixes properly.\n",
    "        \n",
    "        Args:\n",
    "            logits: Model logits (batch_size, sequence_length, num_labels)\n",
    "            attention_mask: Attention mask (batch_size, sequence_length)\n",
    "            \n",
    "        Returns:\n",
    "            List of label sequences with proper BIO tagging\n",
    "        \"\"\"\n",
    "        predictions = torch.argmax(logits, dim=-1)  # (batch_size, sequence_length)\n",
    "        batch_labels = []\n",
    "        \n",
    "        for pred, mask in zip(predictions, attention_mask):\n",
    "            # Only process tokens that aren't padding\n",
    "            valid_length = torch.sum(mask).item()\n",
    "            pred = pred[:valid_length].cpu().tolist()\n",
    "            \n",
    "            # Convert to BIO format\n",
    "            labels = self.decode(pred)\n",
    "            batch_labels.append(labels)\n",
    "            \n",
    "        return batch_labels\n",
    "\n",
    "class PiiDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer, label_mapper: LabelMapper = None, max_length: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label_mapper = label_mapper\n",
    "        \n",
    "        # Validate source_text column\n",
    "        if 'source_text' not in self.data.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'source_text' column\")\n",
    "        \n",
    "        # Ensure source_text is string type\n",
    "        self.data['source_text'] = self.data['source_text'].astype(str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def parse_labels(self, labels_str) -> List[str]:\n",
    "        \"\"\"Safely parse label strings into list of label strings.\"\"\"\n",
    "        try:\n",
    "            if isinstance(labels_str, str):\n",
    "                if '[' in labels_str:\n",
    "                    return ast.literal_eval(labels_str)\n",
    "                return labels_str.split(',')\n",
    "            elif isinstance(labels_str, list):\n",
    "                return labels_str\n",
    "            return ['O'] * self.max_length\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing labels: {e}, value: {labels_str}\")\n",
    "            return ['O'] * self.max_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Ensure text is string type\n",
    "        text = str(row['source_text'])\n",
    "        \n",
    "        # Handle empty strings\n",
    "        if not text.strip():\n",
    "            text = \" \"  # Use single space for empty strings\n",
    "            \n",
    "        try:\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Tokenization error at index {idx}: {e}\")\n",
    "            print(f\"Text: {text}\")\n",
    "            raise\n",
    "        \n",
    "        if 'token_type_ids' in encoding:\n",
    "            del encoding['token_type_ids']\n",
    "            \n",
    "        encoding = {key: value.squeeze(0) for key, value in encoding.items()}\n",
    "        \n",
    "        # Parse and process labels\n",
    "        labels = self.parse_labels(row['mbert_token_classes'])\n",
    "        if self.label_mapper:\n",
    "            labels = self.label_mapper.encode(labels)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "            \n",
    "        if len(labels) < self.max_length:\n",
    "            labels = torch.cat([labels, torch.zeros(self.max_length - len(labels), dtype=torch.long)])\n",
    "        elif len(labels) > self.max_length:\n",
    "            labels = labels[:self.max_length]\n",
    "\n",
    "        return {**encoding, 'labels': labels}\n",
    "\n",
    "class PiiDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df, batch_size=16):\n",
    "        super().__init__()\n",
    "        # Ensure DataFrames are copied to avoid modifying original data\n",
    "        self.train_df = train_df.copy()\n",
    "        self.val_df = val_df.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "        self.label_mapper = LabelMapper()\n",
    "        \n",
    "        # Validate and clean data\n",
    "        self._validate_and_clean_data()\n",
    "\n",
    "    def _validate_and_clean_data(self):\n",
    "        \"\"\"Validate and clean the input DataFrames.\"\"\"\n",
    "        required_columns = ['source_text', 'mbert_token_classes']\n",
    "        \n",
    "        for df_name, df in [('train', self.train_df), ('val', self.val_df)]:\n",
    "            # Check required columns\n",
    "            missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing required columns in {df_name}_df: {missing_cols}\")\n",
    "            \n",
    "            # Convert source_text to string\n",
    "            df['source_text'] = df['source_text'].astype(str)\n",
    "            \n",
    "            # Remove empty rows\n",
    "            empty_mask = df['source_text'].str.strip().eq('')\n",
    "            if empty_mask.any():\n",
    "                print(f\"Warning: Removing {empty_mask.sum()} empty rows from {df_name}_df\")\n",
    "                if df_name == 'train':\n",
    "                    self.train_df = df[~empty_mask].reset_index(drop=True)\n",
    "                else:\n",
    "                    self.val_df = df[~empty_mask].reset_index(drop=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Create and fit label mapper on training data\n",
    "        train_labels = [self.parse_labels(labels) for labels in self.train_df['mbert_token_classes']]\n",
    "        self.label_mapper.fit(train_labels)\n",
    "        \n",
    "        # Create datasets\n",
    "        self.train_dataset = PiiDataset(self.train_df, self.tokenizer, self.label_mapper)\n",
    "        self.val_dataset = PiiDataset(self.val_df, self.tokenizer, self.label_mapper)\n",
    "    \n",
    "    def parse_labels(self, labels_str):\n",
    "        \"\"\"Helper method to parse labels for fitting the mapper.\"\"\"\n",
    "        try:\n",
    "            if isinstance(labels_str, str):\n",
    "                if '[' in labels_str:\n",
    "                    return ast.literal_eval(labels_str)\n",
    "                return labels_str.split(',')\n",
    "            elif isinstance(labels_str, list):\n",
    "                return labels_str\n",
    "            return ['O']\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing labels during setup: {e}\")\n",
    "            return ['O']\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=False,\n",
    "            persistent_workers=False,\n",
    "            prefetch_factor=2\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=2,\n",
    "            pin_memory=False,\n",
    "            persistent_workers=False,\n",
    "            prefetch_factor=2\n",
    "        )\n",
    "\n",
    "class PiiModel(pl.LightningModule):\n",
    "    def __init__(self, num_labels: int, model_name=\"iiiorg/piiranha-v1-detect-personal-information\", lr=2.5e-5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_labels = num_labels\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Load model configuration\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.num_labels = num_labels\n",
    "        config.use_cache = False\n",
    "        \n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        \n",
    "        # Initialize per-label metrics\n",
    "        self.train_metrics = None\n",
    "        self.val_metrics = None\n",
    "        self.test_metrics = None\n",
    "        \n",
    "        # Track best validation metrics\n",
    "        self.best_val_metrics = {}\n",
    "\n",
    "    def _create_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Create metrics including per-label metrics.\"\"\"\n",
    "        metrics = {\n",
    "            'precision': Precision(task=\"multiclass\", num_classes=self.num_labels, average='macro'),\n",
    "            'recall': Recall(task=\"multiclass\", num_classes=self.num_labels, average='macro'),\n",
    "            'f1': F1Score(task=\"multiclass\", num_classes=self.num_labels, average='macro'),\n",
    "            'accuracy': Accuracy(task=\"multiclass\", num_classes=self.num_labels, average='macro')\n",
    "        }\n",
    "        \n",
    "        # Add per-label metrics\n",
    "        for i in range(self.num_labels):\n",
    "            metrics.update({\n",
    "                f'precision_label_{i}': Precision(task=\"multiclass\", num_classes=self.num_labels, average=None),\n",
    "                f'recall_label_{i}': Recall(task=\"multiclass\", num_classes=self.num_labels, average=None),\n",
    "                f'f1_label_{i}': F1Score(task=\"multiclass\", num_classes=self.num_labels, average=None)\n",
    "            })\n",
    "        \n",
    "        return {name: metric.to(self.device) for name, metric in metrics.items()}\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Initialize metrics on the correct device at the start of training.\"\"\"\n",
    "        if self.train_metrics is None:\n",
    "            self.train_metrics = self._create_metrics()\n",
    "        if self.val_metrics is None:\n",
    "            self.val_metrics = self._create_metrics()\n",
    "        if self.test_metrics is None:\n",
    "            self.test_metrics = self._create_metrics()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    def _compute_metrics(self, preds, labels, metrics):\n",
    "        \"\"\"Compute all metrics including per-label metrics.\"\"\"\n",
    "        preds = preds.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        \n",
    "        results = {}\n",
    "        for name, metric in metrics.items():\n",
    "            if 'label_' in name:\n",
    "                # For per-label metrics, get the specific label index\n",
    "                label_idx = int(name.split('_')[-1])\n",
    "                value = metric(preds, labels)[label_idx]\n",
    "                results[name] = value\n",
    "            else:\n",
    "                results[name] = metric(preds, labels)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step.\"\"\"\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Initialize metrics if not already done\n",
    "        if self.train_metrics is None:\n",
    "            self.train_metrics = self._create_metrics()\n",
    "        \n",
    "        # Compute and log metrics\n",
    "        metrics = self._compute_metrics(preds, batch['labels'], self.train_metrics)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        for name, value in metrics.items():\n",
    "            self.log(f\"train_{name}\", value, prog_bar=True)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> None:\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        if self.val_metrics is None:\n",
    "            self.val_metrics = self._create_metrics()\n",
    "        \n",
    "        metrics = self._compute_metrics(preds, batch['labels'], self.val_metrics)\n",
    "        \n",
    "        # Log all metrics\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        for name, value in metrics.items():\n",
    "            self.log(f\"val_{name}\", value, prog_bar=True)\n",
    "        \n",
    "        # Update best metrics if needed\n",
    "        if not self.best_val_metrics or metrics['f1'] > self.best_val_metrics.get('f1', 0):\n",
    "            self.best_val_metrics = metrics\n",
    "\n",
    "    def test_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> None:\n",
    "        \"\"\"Test step.\"\"\"\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Initialize metrics if not already done\n",
    "        if self.test_metrics is None:\n",
    "            self.test_metrics = self._create_metrics()\n",
    "        \n",
    "        # Compute and log metrics\n",
    "        metrics = self._compute_metrics(preds, batch['labels'], self.test_metrics)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log(\"test_loss\", loss)\n",
    "        for name, value in metrics.items():\n",
    "            self.log(f\"test_{name}\", value)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizers and learning rate schedulers.\"\"\"\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def predict_bio_labels(self, input_ids, attention_mask, label_mapper):\n",
    "        \"\"\"Get predictions with proper BIO tagging.\"\"\"\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return label_mapper.decode_with_bio(outputs.logits, attention_mask)\n",
    "\n",
    "def train_pii_model(train_df, val_df, batch_size=16, max_epochs=10, save_dir=\"pii_model\"):\n",
    "    \"\"\"Train the PII model with aggressive memory optimizations.\"\"\"\n",
    "    import gc\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Clear GPU cache and run garbage collection\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    checkpoints_dir = os.path.join(save_dir, \"checkpoints\")\n",
    "    metrics_dir = os.path.join(save_dir, \"metrics\")\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize data module with reduced num_workers\n",
    "    data_module = PiiDataModule(\n",
    "        train_df=train_df,\n",
    "        val_df=val_df,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    data_module.setup()\n",
    "    \n",
    "    # Initialize model with memory optimizations\n",
    "    model = PiiModel(\n",
    "        num_labels=data_module.label_mapper.num_labels,\n",
    "        model_name=\"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "    )\n",
    "    \n",
    "    initial_weights_dir = os.path.join(save_dir, \"initial_weights\")\n",
    "    os.makedirs(initial_weights_dir, exist_ok=True)\n",
    "    model.model.save_pretrained(initial_weights_dir)\n",
    "    print(f\"Initial weights of the model saved to {initial_weights_dir}\")\n",
    "    \n",
    "    # Additional memory optimizations for the model\n",
    "    if device.type == \"cuda\":\n",
    "        model.model.gradient_checkpointing_enable()\n",
    "        # Optimize memory allocation for attention mechanisms\n",
    "        model.model.config.use_cache = False\n",
    "    \n",
    "    label_mapper_path = os.path.join(save_dir, \"label_mapper.json\")\n",
    "    label_mapper_data = {\n",
    "        'label_to_id': data_module.label_mapper.label_to_id,\n",
    "        'id_to_label': data_module.label_mapper.id_to_label,\n",
    "        'num_labels': data_module.label_mapper.num_labels\n",
    "    }\n",
    "    with open(label_mapper_path, 'w') as f:\n",
    "        json.dump(label_mapper_data, f, indent=2)\n",
    "\n",
    "    class EnhancedMetricCheckpoint(pl.callbacks.ModelCheckpoint):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.metrics_history = []\n",
    "            self.last_metrics=None\n",
    "        def on_validation_end(self, trainer, pl_module):\n",
    "            # Always save the current epoch checkpoint\n",
    "            current_epoch = trainer.current_epoch\n",
    "            current_loss = trainer.callback_metrics.get('val_loss', 0.0)\n",
    "            \n",
    "            # Create checkpoint filename\n",
    "            checkpoint_filename = f'checkpoint-epoch-{current_epoch:02d}-loss-{current_loss:.4f}.ckpt'\n",
    "            checkpoint_path = os.path.join(self.dirpath, checkpoint_filename)\n",
    "            \n",
    "            # Save checkpoint\n",
    "            trainer.save_checkpoint(checkpoint_path)\n",
    "            print(f\"\\nSaved checkpoint for epoch {current_epoch}: {checkpoint_filename}\")\n",
    "            \n",
    "            # Collect metrics\n",
    "            metrics = {\n",
    "                'epoch': current_epoch,\n",
    "                'global_step': trainer.global_step,\n",
    "                'timestamp': datetime.datetime.now().isoformat(),\n",
    "                'train_metrics': {},\n",
    "                'val_metrics': {}\n",
    "            }\n",
    "            \n",
    "            for key, value in trainer.callback_metrics.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    value = value.item()\n",
    "                if key.startswith('train_'):\n",
    "                    metrics['train_metrics'][key] = value\n",
    "                elif key.startswith('val_'):\n",
    "                    metrics['val_metrics'][key] = value\n",
    "            \n",
    "            self.metrics_history.append(metrics)\n",
    "            self.last_metrics = metrics\n",
    "            # Save metrics\n",
    "            metrics_file = os.path.join(metrics_dir, f'metrics_epoch_{current_epoch}.json')\n",
    "            with open(metrics_file, 'w') as f:\n",
    "                json.dump(metrics, f, indent=2)\n",
    "            \n",
    "            # Save the model in safetensors format\n",
    "            model_dir = os.path.join(self.dirpath, f'model_epoch_{current_epoch:02d}')\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            config_path = os.path.join(model_dir, 'config.json')\n",
    "            model_weights_path = os.path.join(model_dir, 'model.safetensors')\n",
    "\n",
    "            # Save model configuration\n",
    "            pl_module.model.config.save_pretrained(model_dir)\n",
    "\n",
    "            # Save model weights using safetensors\n",
    "            save_file(pl_module.model.state_dict(), model_weights_path)\n",
    "\n",
    "            print(f\"\\nSaved model configuration and weights for epoch {current_epoch}.\")\n",
    "\n",
    "\n",
    "            # Update best metrics if needed\n",
    "            if self.best_model_path:\n",
    "                best_metrics_file = os.path.join(metrics_dir, 'best_metrics.json')\n",
    "                with open(best_metrics_file, 'w') as f:\n",
    "                    json.dump(metrics, f, indent=2)\n",
    "\n",
    "    \n",
    "    class FinalEpochCallback(pl.Callback):\n",
    "        def on_train_end(self, trainer, pl_module):\n",
    "            # Save final model state\n",
    "            final_model_path = os.path.join(save_dir, \"final_model\")\n",
    "            os.makedirs(final_model_path, exist_ok=True)\n",
    "            pl_module.model.save_pretrained(final_model_path)\n",
    "            print(f\"\\nSaved final model to {final_model_path}\")\n",
    "\n",
    "    # Setup callbacks with reduced checkpoint frequency\n",
    "    checkpoint_callback = EnhancedMetricCheckpoint(\n",
    "        dirpath=checkpoints_dir,\n",
    "        filename='checkpoint-{epoch:02d}-{val_loss:.4f}',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_top_k=3,  # Save top 3 models\n",
    "        save_last=True,  # Save last model\n",
    "        every_n_epochs=1  # Save checkpoint every epoch\n",
    "    )\n",
    "    \n",
    "    early_stopping = DetailedEarlyStopping(\n",
    "        patience=1,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "    \n",
    "    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    \n",
    "    # Setup logger with reduced logging frequency\n",
    "    logger = TensorBoardLogger(\n",
    "        \"tb_logs\", \n",
    "        name=\"piiranha_training\",\n",
    "        log_graph=False,  # Disable computational graph logging\n",
    "        max_queue=10\n",
    "    )\n",
    "    callbacks = [\n",
    "        checkpoint_callback, \n",
    "        early_stopping, \n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "        FinalEpochCallback()\n",
    "    ]\n",
    "    # Initialize trainer with memory optimizations\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "        logger=logger,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=1,\n",
    "        gradient_clip_val=1.0,\n",
    "        log_every_n_steps=50,  # Reduced logging frequency\n",
    "        precision=\"16-mixed\",  # Use mixed precision training with reduced precision\n",
    "        accumulate_grad_batches=2,  # Gradient accumulation to reduce memory usage\n",
    "        strategy='ddp_notebook' if torch.cuda.is_available() else \"auto\",\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=False,  # Disable model summary to save memory\n",
    "        inference_mode=True,  # Enable inference mode optimization\n",
    "        profiler=None,  # Disable profiling\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Modified DataLoader settings in PiiDataModule\n",
    "    data_module.train_dataloader = lambda: DataLoader(\n",
    "        data_module.train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,  # Reduced number of workers\n",
    "        pin_memory=False,  # Disable pin_memory\n",
    "        persistent_workers=False,  # Disable persistent workers\n",
    "        prefetch_factor=2  # Reduced prefetch factor\n",
    "    )\n",
    "    \n",
    "    data_module.val_dataloader = lambda: DataLoader(\n",
    "        data_module.val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=2,\n",
    "        pin_memory=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    \n",
    "    # Print final best metrics\n",
    "    final_metrics = {\n",
    "        'best_metrics': model.best_val_metrics,\n",
    "        'final_metrics': checkpoint_callback.last_metrics if checkpoint_callback.last_metrics else {},\n",
    "        'training_completed': True,\n",
    "        'total_epochs': trainer.current_epoch,\n",
    "        'early_stopped': trainer.should_stop,\n",
    "        'best_model_path': checkpoint_callback.best_model_path,\n",
    "        'last_model_path': checkpoint_callback.last_model_path\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"training_summary.json\"), 'w') as f:\n",
    "        json.dump({k: float(v) if isinstance(v, torch.Tensor) else v \n",
    "                  for k, v in final_metrics.items()}, f, indent=2)\n",
    "    \n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(f\"Total epochs completed: {trainer.current_epoch + 1}\")\n",
    "    print(f\"Best model saved at: {checkpoint_callback.best_model_path}\")\n",
    "    print(\"\\nFinal Best Metrics:\")\n",
    "    for name, value in model.best_val_metrics.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.item()\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "    # Save the model and related files\n",
    "    final_model_path = os.path.join(save_dir, \"final_model\")\n",
    "    os.makedirs(final_model_path, exist_ok=True)\n",
    "    model.model.save_pretrained(final_model_path)\n",
    "    \n",
    "    print(f\"\\nModel saved to {final_model_path}\")\n",
    "    \n",
    "    return model, data_module.label_mapper\n",
    "\n",
    "def load_checkpoint(checkpoint_path: str, model_dir=\"pii_model\"):\n",
    "    \"\"\"\n",
    "    Load a specific checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the checkpoint file\n",
    "        model_dir: Directory containing label_mapper.json and tokenizer files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load label mapper\n",
    "    with open(os.path.join(model_dir, 'label_mapper.json'), 'r') as f:\n",
    "        label_mapper_data = json.load(f)\n",
    "    \n",
    "    label_mapper = LabelMapper()\n",
    "    label_mapper.label_to_id = label_mapper_data['label_to_id']\n",
    "    label_mapper.id_to_label = {int(k): v for k, v in label_mapper_data['id_to_label'].items()}\n",
    "    label_mapper.num_labels = label_mapper_data['num_labels']\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = PiiModel(num_labels=label_mapper.num_labels)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model, tokenizer, label_mapper\n",
    "\n",
    "def list_checkpoints(save_dir=\"pii_model\"):\n",
    "    \"\"\"List all available checkpoints.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    checkpoint_dir = os.path.join(save_dir, \"epoch_checkpoints\")\n",
    "    best_model_dir = os.path.join(save_dir, \"best_model\")\n",
    "    \n",
    "    print(\"Regular checkpoints:\")\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith('.ckpt')])\n",
    "        for ckpt in checkpoints:\n",
    "            print(f\"  - {ckpt}\")\n",
    "    else:\n",
    "        print(\"  No regular checkpoints found\")\n",
    "        \n",
    "    print(\"\\nBest model checkpoints:\")\n",
    "    if os.path.exists(best_model_dir):\n",
    "        checkpoints = sorted([f for f in os.listdir(best_model_dir) if f.endswith('.ckpt')])\n",
    "        for ckpt in checkpoints:\n",
    "            print(f\"  - {ckpt}\")\n",
    "    else:\n",
    "        print(\"  No best model checkpoints found\")\n",
    "\n",
    "def list_saved_metrics(save_dir=\"pii_model\"):\n",
    "    \"\"\"List all saved metrics and checkpoints.\"\"\"\n",
    "    metrics_dir = os.path.join(save_dir, \"metrics\")\n",
    "    checkpoints_dir = os.path.join(save_dir, \"checkpoints\")\n",
    "    \n",
    "    print(\"Available metric files:\")\n",
    "    if os.path.exists(metrics_dir):\n",
    "        metric_files = sorted([f for f in os.listdir(metrics_dir) if f.endswith('.json')])\n",
    "        for file in metric_files:\n",
    "            print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(\"  No metric files found\")\n",
    "    \n",
    "    print(\"\\nAvailable checkpoints:\")\n",
    "    if os.path.exists(checkpoints_dir):\n",
    "        checkpoint_files = sorted([f for f in os.listdir(checkpoints_dir) if f.endswith('.ckpt')])\n",
    "        for file in checkpoint_files:\n",
    "            print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(\"  No checkpoints found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]='expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325517\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(len(train_df))\n",
    "val_df = pd.read_csv('validation.csv')\n",
    "\n",
    "def contains_labels(privacy_mask_str):\n",
    "    try:\n",
    "        # Convert the string representation to a list of dictionaries\n",
    "        privacy_mask = ast.literal_eval(privacy_mask_str)\n",
    "        # Check if any label is ACCOUNTNUM or IDCARTNUM\n",
    "        return any(item['label'] in ['ACCOUNTNUM', 'IDCARDNUM'] for item in privacy_mask)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return False\n",
    "\n",
    "# Apply the filtering function to the DataFrame\n",
    "filtered_train_df = train_df[train_df['privacy_mask'].apply(contains_labels)]\n",
    "filtered_val_df = val_df[val_df['privacy_mask'].apply(contains_labels)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3422564/165425424.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_train_df['mbert_token_classes'] = filtered_train_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))\n",
      "/tmp/ipykernel_3422564/165425424.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_val_df['mbert_token_classes'] = filtered_val_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))\n"
     ]
    }
   ],
   "source": [
    "def filter_labels(labels_str, valid_labels):\n",
    "    try:\n",
    "        if isinstance(labels_str, str):\n",
    "            labels = ast.literal_eval(labels_str)\n",
    "        elif isinstance(labels_str, list):\n",
    "            labels = labels_str\n",
    "        else:\n",
    "            return ['O'] * 128  # Assuming max length of 128\n",
    "\n",
    "        # Replace labels not in valid_labels with 'O'\n",
    "        return [label if label in valid_labels else 'O' for label in labels]\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing labels: {e}, value: {labels_str}\")\n",
    "        return ['O'] * 128  # Assuming max length of 128\n",
    "valid_labels = ['O', 'B-ACCOUNTNUM', 'I-ACCOUNTNUM', 'B-IDCARDNUM', 'I-IDCARDNUM']\n",
    "filtered_train_df['mbert_token_classes'] = filtered_train_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))\n",
    "filtered_val_df['mbert_token_classes'] = filtered_val_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6609dc4bc60c48ae8c0ab4a7d7e058a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfa23e71e2b464689f4dff5e8d3e58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098ae27063a14997b33f85e2a18a084b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6c82eda9eb4f7f898c71d6e1909114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 unique base labels (excluding O)\n",
      "Total number of labels after mapping: 3\n",
      "\n",
      "Label mapping:\n",
      "B-ACCOUNTNUM: 1\n",
      "B-IDCARDNUM: 2\n",
      "I-ACCOUNTNUM: 1\n",
      "I-IDCARDNUM: 2\n",
      "O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at iiiorg/piiranha-v1-detect-personal-information and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([18]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([18, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights of the model saved to pii_model/initial_weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W CUDAAllocatorConfig.h:30] Warning: expandable_segments not supported on this platform (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 unique base labels (excluding O)\n",
      "Total number of labels after mapping: 3\n",
      "\n",
      "Label mapping:\n",
      "B-ACCOUNTNUM: 1\n",
      "B-IDCARDNUM: 2\n",
      "I-ACCOUNTNUM: 1\n",
      "I-IDCARDNUM: 2\n",
      "O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /teamspace/studios/this_studio/pii_model/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ae2686b0c44c4a8486fa2daeb1c892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision_label_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall_label_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1_label_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision_label_1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall_label_1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1_label_1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision_label_2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall_label_2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1_label_2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 0: checkpoint-epoch-00-loss-0.4331.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067f2c5912774179abd6d056cc90cb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e962d787d8448e844be75040357bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 0: checkpoint-epoch-00-loss-0.0230.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a251c3b102794cca931c72966cefb044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 1: checkpoint-epoch-01-loss-0.0207.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 1.\n"
     ]
    }
   ],
   "source": [
    "model, label_mapper = train_pii_model(filtered_train_df, filtered_val_df,batch_size=32, save_dir=\"pii_model\", max_epochs=10)\n",
    "\n",
    "list_saved_metrics() # Best metrics and best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the config\n",
    "config = AutoConfig.from_pretrained(\"pii_model/checkpoints/model_epoch_03\")\n",
    "\n",
    "# Initialize the model with the config\n",
    "model = AutoModelForTokenClassification.from_config(config)\n",
    "\n",
    "# Load the safetensors weights\n",
    "state_dict = load_file(\"pii_model/checkpoints/model_epoch_03/model.safetensors\")\n",
    "\n",
    "# Load the state dict into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "\n",
    "# Load the label mapper if needed\n",
    "with open(\"pii_model/label_mapper.json\", 'r') as f:\n",
    "    label_mapper_data = json.load(f)\n",
    "\n",
    "label_mapper = LabelMapper()\n",
    "label_mapper.label_to_id = label_mapper_data['label_to_id']\n",
    "label_mapper.id_to_label = {int(k): v for k, v in label_mapper_data['id_to_label'].items()}\n",
    "label_mapper.num_labels = label_mapper_data['num_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: <p>Validatie ID: 663148812, Sociale beveiliging: 862460623.</p><p>Vertrek via: Duplex 69, Schiedam, 156.</p>\n",
      "\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-IDCARDNUM', 'I-IDCARDNUM', 'I-IDCARDNUM', 'I-IDCARDNUM', 'I-IDCARDNUM', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Token-label alignment:\n",
      "[CLS]: O\n",
      "<: O\n",
      "p: O\n",
      ">: O\n",
      "Val: O\n",
      "##idat: O\n",
      "##ie: O\n",
      "ID: O\n",
      ":: B-IDCARDNUM\n",
      "663: I-IDCARDNUM\n",
      "##14: I-IDCARDNUM\n",
      "##8: I-IDCARDNUM\n",
      "##8: I-IDCARDNUM\n",
      "##12: O\n",
      ",: O\n",
      "Sociale: O\n",
      "be: O\n",
      "##vei: O\n",
      "##ligi: O\n",
      "##ng: O\n",
      ":: O\n",
      "862: O\n",
      "##46: O\n",
      "##0: O\n",
      "##6: O\n",
      "##23: O\n",
      ".: O\n",
      "<: O\n",
      "/: O\n",
      "p: O\n",
      ">: O\n",
      "<: O\n",
      "p: O\n",
      ">: O\n",
      "Vert: O\n",
      "##rek: O\n",
      "via: O\n",
      ":: O\n",
      "Du: O\n",
      "##plex: O\n",
      "69: O\n",
      ",: O\n",
      "Sc: O\n",
      "##hie: O\n",
      "##dam: O\n",
      ",: O\n",
      "156: O\n",
      ".: O\n",
      "<: O\n",
      "/: O\n",
      "p: O\n",
      ">: O\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Get the text\n",
    "text = filtered_val_df.iloc[27].source_text\n",
    "\n",
    "\n",
    "# Tokenize with padding and truncation\n",
    "encoded_text = tokenizer(\n",
    "    text,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,  # or whatever max_length you used during training\n",
    "    return_tensors=\"pt\"  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Move inputs to the same device as model\n",
    "inputs = {\n",
    "    'input_ids': encoded_text['input_ids'].to(device),\n",
    "    'attention_mask': encoded_text['attention_mask'].to(device)\n",
    "}\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predictions\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Convert predictions to labels using label_mapper\n",
    "predicted_labels = label_mapper.decode(predictions[0].cpu().tolist())\n",
    "\n",
    "# Print results\n",
    "print(\"Original text:\", text)\n",
    "print(\"\\nPredicted labels:\", predicted_labels)\n",
    "\n",
    "# If you want to see the token-label alignment:\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text['input_ids'][0])\n",
    "print(\"\\nToken-label alignment:\")\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    if token != '[PAD]':  # Skip padding tokens\n",
    "        print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy dependant Piidgeon training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]='expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetailedEarlyStopping(EarlyStopping):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_metrics = None\n",
    "\n",
    "    def _run_early_stopping_check(self, trainer):\n",
    "        stop_training = super()._run_early_stopping_check(trainer)\n",
    "        \n",
    "        if stop_training:\n",
    "            print(\"\\nEarly stopping triggered! Saving best model and metrics...\")\n",
    "            \n",
    "            # Save the model\n",
    "            best_model_path = os.path.join(trainer.checkpoint_callback.dirpath, 'best_model_early_stop')\n",
    "            trainer.lightning_module.model.save_pretrained(best_model_path)\n",
    "            \n",
    "            # Store best metrics\n",
    "            self.best_metrics = {\n",
    "                name: value.item() if hasattr(value, 'item') else value\n",
    "                for name, value in trainer.callback_metrics.items()\n",
    "            }\n",
    "            \n",
    "            # Print detailed metrics\n",
    "            print(\"\\nBest Model Metrics:\")\n",
    "            for name, value in self.best_metrics.items():\n",
    "                print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "        return stop_training\n",
    "\n",
    "class LabelMapper:\n",
    "    def __init__(self):\n",
    "        # Start with 'O' as it's always present\n",
    "        self.label_to_id: Dict[str, int] = {'O': 0}\n",
    "        self.id_to_label: Dict[int, str] = {0: 'O'}\n",
    "        self.num_labels: int = 1\n",
    "        \n",
    "    def fit(self, label_sequences: List[List[str]]) -> None:\n",
    "        \"\"\"\n",
    "        Fit the mapper on a list of label sequences, combining B- and I- prefixes.\n",
    "        Args:\n",
    "            label_sequences: List of label sequences, where each sequence is a list of string labels\n",
    "        \"\"\"\n",
    "        # Collect all unique base labels (without B- or I- prefixes)\n",
    "        base_labels = set()\n",
    "        for sequence in label_sequences:\n",
    "            for label in sequence:\n",
    "                if label != 'O':\n",
    "                    # Strip B- or I- prefix and add base label\n",
    "                    base_label = label[2:] if label.startswith(('B-', 'I-')) else label\n",
    "                    base_labels.add(base_label)\n",
    "        \n",
    "        # Sort base labels for consistency\n",
    "        sorted_base_labels = sorted(base_labels)\n",
    "        \n",
    "        # Create mappings for O, B- and I- variants\n",
    "        label_mappings = {'O': 0}  # Start with O\n",
    "        current_idx = 1\n",
    "        \n",
    "        # Create id_to_label mapping that properly preserves B- prefixes\n",
    "        id_to_label_mapping = {0: 'O'}\n",
    "\n",
    "        for base_label in sorted_base_labels:\n",
    "            # Add B- and I- variants with same index\n",
    "            b_label = f'B-{base_label}'\n",
    "            i_label = f'I-{base_label}'\n",
    "            label_mappings[b_label] = current_idx\n",
    "            label_mappings[i_label] = current_idx\n",
    "            # Store the B- variant in id_to_label mapping\n",
    "            id_to_label_mapping[current_idx] = b_label\n",
    "            current_idx += 1\n",
    "            \n",
    "        # Store mappings\n",
    "        self.label_to_id = label_mappings\n",
    "        self.id_to_label = id_to_label_mapping\n",
    "        self.num_labels = current_idx\n",
    "        \n",
    "        # Print mapping information\n",
    "        print(f\"\\nFound {len(base_labels)} unique base labels (excluding O)\")\n",
    "        print(f\"Total number of labels after mapping: {self.num_labels}\")\n",
    "        print(\"\\nLabel mapping:\")\n",
    "        for label, idx in sorted(self.label_to_id.items()):\n",
    "            print(f\"{label}: {idx}\")\n",
    "\n",
    "    def encode(self, labels: List[str]) -> List[int]:\n",
    "        \"\"\"Convert string labels to IDs, maintaining B-/I- sequence.\"\"\"\n",
    "        return [self.label_to_id[label] for label in labels]\n",
    "\n",
    "    def decode(self, ids: List[int]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert IDs back to string labels.\n",
    "        For non-O labels, uses B- prefix for first token of an entity,\n",
    "        I- prefix for subsequent tokens of the same entity.\n",
    "        \"\"\"\n",
    "        decoded_labels = []\n",
    "        prev_id = 0  # O tag\n",
    "        \n",
    "        for id in ids:\n",
    "            if id == 0:\n",
    "                decoded_labels.append('O')\n",
    "                prev_id = 0\n",
    "            else:\n",
    "                base_label = self.id_to_label[id][2:]  # Strip B- prefix from stored label\n",
    "                if id != prev_id:\n",
    "                    # New entity starts\n",
    "                    decoded_labels.append(f'B-{base_label}')\n",
    "                else:\n",
    "                    # Continue existing entity\n",
    "                    decoded_labels.append(f'I-{base_label}')\n",
    "                prev_id = id\n",
    "                \n",
    "        return decoded_labels\n",
    "\n",
    "    def decode_with_bio(self, logits: torch.Tensor, attention_mask: torch.Tensor) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Decode model logits to BIO labels, handling B-/I- prefixes properly.\n",
    "        \n",
    "        Args:\n",
    "            logits: Model logits (batch_size, sequence_length, num_labels)\n",
    "            attention_mask: Attention mask (batch_size, sequence_length)\n",
    "            \n",
    "        Returns:\n",
    "            List of label sequences with proper BIO tagging\n",
    "        \"\"\"\n",
    "        predictions = torch.argmax(logits, dim=-1)  # (batch_size, sequence_length)\n",
    "        batch_labels = []\n",
    "        \n",
    "        for pred, mask in zip(predictions, attention_mask):\n",
    "            # Only process tokens that aren't padding\n",
    "            valid_length = torch.sum(mask).item()\n",
    "            pred = pred[:valid_length].cpu().tolist()\n",
    "            \n",
    "            # Convert to BIO format\n",
    "            labels = self.decode(pred)\n",
    "            batch_labels.append(labels)\n",
    "            \n",
    "        return batch_labels\n",
    "\n",
    "class PiiDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer, label_mapper: LabelMapper = None, max_length: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label_mapper = label_mapper\n",
    "        \n",
    "        # Validate source_text column\n",
    "        if 'source_text' not in self.data.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'source_text' column\")\n",
    "        \n",
    "        # Ensure source_text is string type\n",
    "        self.data['source_text'] = self.data['source_text'].astype(str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def parse_labels(self, labels_str) -> List[str]:\n",
    "        \"\"\"Safely parse label strings into list of label strings.\"\"\"\n",
    "        try:\n",
    "            if isinstance(labels_str, str):\n",
    "                if '[' in labels_str:\n",
    "                    return ast.literal_eval(labels_str)\n",
    "                return labels_str.split(',')\n",
    "            elif isinstance(labels_str, list):\n",
    "                return labels_str\n",
    "            return ['O'] * self.max_length\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing labels: {e}, value: {labels_str}\")\n",
    "            return ['O'] * self.max_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Ensure text is string type\n",
    "        text = str(row['source_text'])\n",
    "        \n",
    "        # Handle empty strings\n",
    "        if not text.strip():\n",
    "            text = \" \"  # Use single space for empty strings\n",
    "            \n",
    "        try:\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Tokenization error at index {idx}: {e}\")\n",
    "            print(f\"Text: {text}\")\n",
    "            raise\n",
    "        \n",
    "        if 'token_type_ids' in encoding:\n",
    "            del encoding['token_type_ids']\n",
    "            \n",
    "        encoding = {key: value.squeeze(0) for key, value in encoding.items()}\n",
    "        \n",
    "        # Parse and process labels\n",
    "        labels = self.parse_labels(row['mbert_token_classes'])\n",
    "        if self.label_mapper:\n",
    "            labels = self.label_mapper.encode(labels)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "            \n",
    "        if len(labels) < self.max_length:\n",
    "            labels = torch.cat([labels, torch.zeros(self.max_length - len(labels), dtype=torch.long)])\n",
    "        elif len(labels) > self.max_length:\n",
    "            labels = labels[:self.max_length]\n",
    "\n",
    "        return {**encoding, 'labels': labels}\n",
    "\n",
    "class PiiDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df, batch_size=16):\n",
    "        super().__init__()\n",
    "        # Ensure DataFrames are copied to avoid modifying original data\n",
    "        self.train_df = train_df.copy()\n",
    "        self.val_df = val_df.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "        self.label_mapper = LabelMapper()\n",
    "        \n",
    "        # Validate and clean data\n",
    "        self._validate_and_clean_data()\n",
    "\n",
    "    def _validate_and_clean_data(self):\n",
    "        \"\"\"Validate and clean the input DataFrames.\"\"\"\n",
    "        required_columns = ['source_text', 'mbert_token_classes']\n",
    "        \n",
    "        for df_name, df in [('train', self.train_df), ('val', self.val_df)]:\n",
    "            # Check required columns\n",
    "            missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing required columns in {df_name}_df: {missing_cols}\")\n",
    "            \n",
    "            # Convert source_text to string\n",
    "            df['source_text'] = df['source_text'].astype(str)\n",
    "            \n",
    "            # Remove empty rows\n",
    "            empty_mask = df['source_text'].str.strip().eq('')\n",
    "            if empty_mask.any():\n",
    "                print(f\"Warning: Removing {empty_mask.sum()} empty rows from {df_name}_df\")\n",
    "                if df_name == 'train':\n",
    "                    self.train_df = df[~empty_mask].reset_index(drop=True)\n",
    "                else:\n",
    "                    self.val_df = df[~empty_mask].reset_index(drop=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Create and fit label mapper on training data\n",
    "        train_labels = [self.parse_labels(labels) for labels in self.train_df['mbert_token_classes']]\n",
    "        self.label_mapper.fit(train_labels)\n",
    "        \n",
    "        # Create datasets\n",
    "        self.train_dataset = PiiDataset(self.train_df, self.tokenizer, self.label_mapper)\n",
    "        self.val_dataset = PiiDataset(self.val_df, self.tokenizer, self.label_mapper)\n",
    "    \n",
    "    def parse_labels(self, labels_str):\n",
    "        \"\"\"Helper method to parse labels for fitting the mapper.\"\"\"\n",
    "        try:\n",
    "            if isinstance(labels_str, str):\n",
    "                if '[' in labels_str:\n",
    "                    return ast.literal_eval(labels_str)\n",
    "                return labels_str.split(',')\n",
    "            elif isinstance(labels_str, list):\n",
    "                return labels_str\n",
    "            return ['O']\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing labels during setup: {e}\")\n",
    "            return ['O']\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=False,\n",
    "            persistent_workers=False,\n",
    "            prefetch_factor=2\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=2,\n",
    "            pin_memory=False,\n",
    "            persistent_workers=False,\n",
    "            prefetch_factor=2\n",
    "        )\n",
    "\n",
    "class PiiModel(pl.LightningModule):\n",
    "    def __init__(self, num_labels: int, model_name=\"iiiorg/piiranha-v1-detect-personal-information\", lr=2.5e-5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_labels = num_labels\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Load model configuration\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        config.num_labels = num_labels\n",
    "        config.use_cache = False\n",
    "        \n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        \n",
    "        # Initialize per-label metrics\n",
    "        self.train_metrics = None\n",
    "        self.val_metrics = None\n",
    "        self.test_metrics = None\n",
    "        \n",
    "        # Track best validation metrics\n",
    "        self.best_val_metrics = {}\n",
    "\n",
    "    def _create_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Create metrics including per-label metrics.\"\"\"\n",
    "        metrics = {\n",
    "            'precision': Precision(task=\"multiclass\", num_classes=self.num_labels, average='macro'),\n",
    "            'recall': Recall(task=\"multiclass\", num_classes=self.num_labels, average='macro'),\n",
    "            'f1': F1Score(task=\"multiclass\", num_classes=self.num_labels, average='macro'),\n",
    "            'accuracy': Accuracy(task=\"multiclass\", num_classes=self.num_labels, average='macro')\n",
    "        }\n",
    "        \n",
    "        # Add per-label metrics\n",
    "        for i in range(self.num_labels):\n",
    "            metrics.update({\n",
    "                f'precision_label_{i}': Precision(task=\"multiclass\", num_classes=self.num_labels, average=None),\n",
    "                f'recall_label_{i}': Recall(task=\"multiclass\", num_classes=self.num_labels, average=None),\n",
    "                f'f1_label_{i}': F1Score(task=\"multiclass\", num_classes=self.num_labels, average=None)\n",
    "            })\n",
    "        \n",
    "        return {name: metric.to(self.device) for name, metric in metrics.items()}\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Initialize metrics on the correct device at the start of training.\"\"\"\n",
    "        if self.train_metrics is None:\n",
    "            self.train_metrics = self._create_metrics()\n",
    "        if self.val_metrics is None:\n",
    "            self.val_metrics = self._create_metrics()\n",
    "        if self.test_metrics is None:\n",
    "            self.test_metrics = self._create_metrics()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    def _compute_metrics(self, preds, labels, metrics):\n",
    "        \"\"\"Compute all metrics including per-label metrics.\"\"\"\n",
    "        preds = preds.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        \n",
    "        results = {}\n",
    "        for name, metric in metrics.items():\n",
    "            if 'label_' in name:\n",
    "                # For per-label metrics, get the specific label index\n",
    "                label_idx = int(name.split('_')[-1])\n",
    "                value = metric(preds, labels)[label_idx]\n",
    "                results[name] = value\n",
    "            else:\n",
    "                results[name] = metric(preds, labels)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step.\"\"\"\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Initialize metrics if not already done\n",
    "        if self.train_metrics is None:\n",
    "            self.train_metrics = self._create_metrics()\n",
    "        \n",
    "        # Compute and log metrics\n",
    "        metrics = self._compute_metrics(preds, batch['labels'], self.train_metrics)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        for name, value in metrics.items():\n",
    "            self.log(f\"train_{name}\", value, prog_bar=True)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> None:\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        if self.val_metrics is None:\n",
    "            self.val_metrics = self._create_metrics()\n",
    "        \n",
    "        metrics = self._compute_metrics(preds, batch['labels'], self.val_metrics)\n",
    "        \n",
    "        # Log all metrics\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        for name, value in metrics.items():\n",
    "            self.log(f\"val_{name}\", value, prog_bar=True)\n",
    "        \n",
    "        # Update best metrics if needed\n",
    "        if not self.best_val_metrics or metrics['f1'] > self.best_val_metrics.get('f1', 0):\n",
    "            self.best_val_metrics = metrics\n",
    "\n",
    "    def test_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> None:\n",
    "        \"\"\"Test step.\"\"\"\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Initialize metrics if not already done\n",
    "        if self.test_metrics is None:\n",
    "            self.test_metrics = self._create_metrics()\n",
    "        \n",
    "        # Compute and log metrics\n",
    "        metrics = self._compute_metrics(preds, batch['labels'], self.test_metrics)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log(\"test_loss\", loss)\n",
    "        for name, value in metrics.items():\n",
    "            self.log(f\"test_{name}\", value)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizers and learning rate schedulers.\"\"\"\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def predict_bio_labels(self, input_ids, attention_mask, label_mapper):\n",
    "        \"\"\"Get predictions with proper BIO tagging.\"\"\"\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return label_mapper.decode_with_bio(outputs.logits, attention_mask)\n",
    "\n",
    "def train_pii_model(train_df, val_df, batch_size=16, max_epochs=10, save_dir=\"pii_model\"):\n",
    "    \"\"\"Train the PII model with aggressive memory optimizations.\"\"\"\n",
    "    import gc\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Clear GPU cache and run garbage collection\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    checkpoints_dir = os.path.join(save_dir, \"checkpoints\")\n",
    "    metrics_dir = os.path.join(save_dir, \"metrics\")\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize data module with reduced num_workers\n",
    "    data_module = PiiDataModule(\n",
    "        train_df=train_df,\n",
    "        val_df=val_df,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    data_module.setup()\n",
    "    \n",
    "    # Initialize model with memory optimizations\n",
    "    model = PiiModel(\n",
    "        num_labels=data_module.label_mapper.num_labels,\n",
    "        model_name=\"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "    )\n",
    "    \n",
    "    initial_weights_dir = os.path.join(save_dir, \"initial_weights\")\n",
    "    os.makedirs(initial_weights_dir, exist_ok=True)\n",
    "    model.model.save_pretrained(initial_weights_dir)\n",
    "    print(f\"Initial weights of the model saved to {initial_weights_dir}\")\n",
    "    \n",
    "    # Additional memory optimizations for the model\n",
    "    if device.type == \"cuda\":\n",
    "        model.model.gradient_checkpointing_enable()\n",
    "        # Optimize memory allocation for attention mechanisms\n",
    "        model.model.config.use_cache = False\n",
    "    \n",
    "    label_mapper_path = os.path.join(save_dir, \"label_mapper.json\")\n",
    "    label_mapper_data = {\n",
    "        'label_to_id': data_module.label_mapper.label_to_id,\n",
    "        'id_to_label': data_module.label_mapper.id_to_label,\n",
    "        'num_labels': data_module.label_mapper.num_labels\n",
    "    }\n",
    "    with open(label_mapper_path, 'w') as f:\n",
    "        json.dump(label_mapper_data, f, indent=2)\n",
    "\n",
    "    class EnhancedMetricCheckpoint(pl.callbacks.ModelCheckpoint):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.metrics_history = []\n",
    "            self.last_metrics=None\n",
    "        def on_validation_end(self, trainer, pl_module):\n",
    "            # Always save the current epoch checkpoint\n",
    "            current_epoch = trainer.current_epoch\n",
    "            current_loss = trainer.callback_metrics.get('val_loss', 0.0)\n",
    "            \n",
    "            # Create checkpoint filename\n",
    "            checkpoint_filename = f'checkpoint-epoch-{current_epoch:02d}-loss-{current_loss:.4f}.ckpt'\n",
    "            checkpoint_path = os.path.join(self.dirpath, checkpoint_filename)\n",
    "            \n",
    "            # Save checkpoint\n",
    "            trainer.save_checkpoint(checkpoint_path)\n",
    "            print(f\"\\nSaved checkpoint for epoch {current_epoch}: {checkpoint_filename}\")\n",
    "            \n",
    "            # Collect metrics\n",
    "            metrics = {\n",
    "                'epoch': current_epoch,\n",
    "                'global_step': trainer.global_step,\n",
    "                'timestamp': datetime.datetime.now().isoformat(),\n",
    "                'train_metrics': {},\n",
    "                'val_metrics': {}\n",
    "            }\n",
    "            \n",
    "            for key, value in trainer.callback_metrics.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    value = value.item()\n",
    "                if key.startswith('train_'):\n",
    "                    metrics['train_metrics'][key] = value\n",
    "                elif key.startswith('val_'):\n",
    "                    metrics['val_metrics'][key] = value\n",
    "            \n",
    "            self.metrics_history.append(metrics)\n",
    "            self.last_metrics = metrics\n",
    "            # Save metrics\n",
    "            metrics_file = os.path.join(metrics_dir, f'metrics_epoch_{current_epoch}.json')\n",
    "            with open(metrics_file, 'w') as f:\n",
    "                json.dump(metrics, f, indent=2)\n",
    "            \n",
    "            # Save the model in safetensors format\n",
    "            model_dir = os.path.join(self.dirpath, f'model_epoch_{current_epoch:02d}')\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            config_path = os.path.join(model_dir, 'config.json')\n",
    "            model_weights_path = os.path.join(model_dir, 'model.safetensors')\n",
    "\n",
    "            # Save model configuration\n",
    "            pl_module.model.config.save_pretrained(model_dir)\n",
    "\n",
    "            # Save model weights using safetensors\n",
    "            save_file(pl_module.model.state_dict(), model_weights_path)\n",
    "\n",
    "            print(f\"\\nSaved model configuration and weights for epoch {current_epoch}.\")\n",
    "\n",
    "\n",
    "            # Update best metrics if needed\n",
    "            if self.best_model_path:\n",
    "                best_metrics_file = os.path.join(metrics_dir, 'best_metrics.json')\n",
    "                with open(best_metrics_file, 'w') as f:\n",
    "                    json.dump(metrics, f, indent=2)\n",
    "\n",
    "    \n",
    "    class FinalEpochCallback(pl.Callback):\n",
    "        def on_train_end(self, trainer, pl_module):\n",
    "            # Save final model state\n",
    "            final_model_path = os.path.join(save_dir, \"final_model\")\n",
    "            os.makedirs(final_model_path, exist_ok=True)\n",
    "            pl_module.model.save_pretrained(final_model_path)\n",
    "            print(f\"\\nSaved final model to {final_model_path}\")\n",
    "\n",
    "    # Setup callbacks with reduced checkpoint frequency\n",
    "    checkpoint_callback = EnhancedMetricCheckpoint(\n",
    "        dirpath=checkpoints_dir,\n",
    "        filename='checkpoint-{epoch:02d}-{val_loss:.4f}',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_top_k=3,  # Save top 3 models\n",
    "        save_last=True,  # Save last model\n",
    "        every_n_epochs=1  # Save checkpoint every epoch\n",
    "    )\n",
    "    \n",
    "    early_stopping = DetailedEarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=2,\n",
    "        mode=\"min\"\n",
    "\n",
    "    )\n",
    "    \n",
    "    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    \n",
    "    # Setup logger with reduced logging frequency\n",
    "    logger = TensorBoardLogger(\n",
    "        \"tb_logs\", \n",
    "        name=\"piiranha_training\",\n",
    "        log_graph=False,  # Disable computational graph logging\n",
    "        max_queue=10\n",
    "    )\n",
    "    callbacks = [\n",
    "        checkpoint_callback, \n",
    "        early_stopping, \n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "        FinalEpochCallback()\n",
    "    ]\n",
    "    # Initialize trainer with memory optimizations\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "        logger=logger,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=1,\n",
    "        gradient_clip_val=1.0,\n",
    "        log_every_n_steps=50,  # Reduced logging frequency\n",
    "        precision=\"16-mixed\",  # Use mixed precision training with reduced precision\n",
    "        accumulate_grad_batches=2,  # Gradient accumulation to reduce memory usage\n",
    "        strategy='ddp_notebook' if torch.cuda.is_available() else \"auto\",\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=False,  # Disable model summary to save memory\n",
    "        inference_mode=True,  # Enable inference mode optimization\n",
    "        profiler=None,  # Disable profiling\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Modified DataLoader settings in PiiDataModule\n",
    "    data_module.train_dataloader = lambda: DataLoader(\n",
    "        data_module.train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,  # Reduced number of workers\n",
    "        pin_memory=False,  # Disable pin_memory\n",
    "        persistent_workers=False,  # Disable persistent workers\n",
    "        prefetch_factor=2  # Reduced prefetch factor\n",
    "    )\n",
    "    \n",
    "    data_module.val_dataloader = lambda: DataLoader(\n",
    "        data_module.val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=2,\n",
    "        pin_memory=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    \n",
    "    # Print final best metrics\n",
    "    final_metrics = {\n",
    "        'best_metrics': model.best_val_metrics,\n",
    "        'final_metrics': checkpoint_callback.last_metrics if checkpoint_callback.last_metrics else {},\n",
    "        'training_completed': True,\n",
    "        'total_epochs': trainer.current_epoch,\n",
    "        'early_stopped': trainer.should_stop,\n",
    "        'best_model_path': checkpoint_callback.best_model_path,\n",
    "        'last_model_path': checkpoint_callback.last_model_path\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, \"training_summary.json\"), 'w') as f:\n",
    "        json.dump({k: float(v) if isinstance(v, torch.Tensor) else v \n",
    "                  for k, v in final_metrics.items()}, f, indent=2)\n",
    "    \n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(f\"Total epochs completed: {trainer.current_epoch + 1}\")\n",
    "    print(f\"Best model saved at: {checkpoint_callback.best_model_path}\")\n",
    "    print(\"\\nFinal Best Metrics:\")\n",
    "    for name, value in model.best_val_metrics.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.item()\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "    # Save the model and related files\n",
    "    final_model_path = os.path.join(save_dir, \"final_model\")\n",
    "    os.makedirs(final_model_path, exist_ok=True)\n",
    "    model.model.save_pretrained(final_model_path)\n",
    "    \n",
    "    print(f\"\\nModel saved to {final_model_path}\")\n",
    "    \n",
    "    return model, data_module.label_mapper\n",
    "\n",
    "def load_checkpoint(checkpoint_path: str, model_dir=\"pii_model\"):\n",
    "    \"\"\"\n",
    "    Load a specific checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the checkpoint file\n",
    "        model_dir: Directory containing label_mapper.json and tokenizer files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load label mapper\n",
    "    with open(os.path.join(model_dir, 'label_mapper.json'), 'r') as f:\n",
    "        label_mapper_data = json.load(f)\n",
    "    \n",
    "    label_mapper = LabelMapper()\n",
    "    label_mapper.label_to_id = label_mapper_data['label_to_id']\n",
    "    label_mapper.id_to_label = {int(k): v for k, v in label_mapper_data['id_to_label'].items()}\n",
    "    label_mapper.num_labels = label_mapper_data['num_labels']\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = PiiModel(num_labels=label_mapper.num_labels)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model, tokenizer, label_mapper\n",
    "\n",
    "def list_checkpoints(save_dir=\"pii_model\"):\n",
    "    \"\"\"List all available checkpoints.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    checkpoint_dir = os.path.join(save_dir, \"epoch_checkpoints\")\n",
    "    best_model_dir = os.path.join(save_dir, \"best_model\")\n",
    "    \n",
    "    print(\"Regular checkpoints:\")\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith('.ckpt')])\n",
    "        for ckpt in checkpoints:\n",
    "            print(f\"  - {ckpt}\")\n",
    "    else:\n",
    "        print(\"  No regular checkpoints found\")\n",
    "        \n",
    "    print(\"\\nBest model checkpoints:\")\n",
    "    if os.path.exists(best_model_dir):\n",
    "        checkpoints = sorted([f for f in os.listdir(best_model_dir) if f.endswith('.ckpt')])\n",
    "        for ckpt in checkpoints:\n",
    "            print(f\"  - {ckpt}\")\n",
    "    else:\n",
    "        print(\"  No best model checkpoints found\")\n",
    "\n",
    "def list_saved_metrics(save_dir=\"pii_model\"):\n",
    "    \"\"\"List all saved metrics and checkpoints.\"\"\"\n",
    "    metrics_dir = os.path.join(save_dir, \"metrics\")\n",
    "    checkpoints_dir = os.path.join(save_dir, \"checkpoints\")\n",
    "    \n",
    "    print(\"Available metric files:\")\n",
    "    if os.path.exists(metrics_dir):\n",
    "        metric_files = sorted([f for f in os.listdir(metrics_dir) if f.endswith('.json')])\n",
    "        for file in metric_files:\n",
    "            print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(\"  No metric files found\")\n",
    "    \n",
    "    print(\"\\nAvailable checkpoints:\")\n",
    "    if os.path.exists(checkpoints_dir):\n",
    "        checkpoint_files = sorted([f for f in os.listdir(checkpoints_dir) if f.endswith('.ckpt')])\n",
    "        for file in checkpoint_files:\n",
    "            print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(\"  No checkpoints found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325517\n",
      "31440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7898"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(len(train_df))\n",
    "val_df = pd.read_csv('validation.csv')\n",
    "\n",
    "def contains_labels(privacy_mask_str):\n",
    "    try:\n",
    "        # Convert the string representation to a list of dictionaries\n",
    "        privacy_mask = ast.literal_eval(privacy_mask_str)\n",
    "        # Check if any label is ACCOUNTNUM or IDCARTNUM\n",
    "        return any(item['label'] in ['ACCOUNTNUM', 'IDCARDNUM'] for item in privacy_mask)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return False\n",
    "\n",
    "# Apply the filtering function to the DataFrame\n",
    "filtered_train_df = train_df[train_df['privacy_mask'].apply(contains_labels)]\n",
    "filtered_val_df = val_df[val_df['privacy_mask'].apply(contains_labels)]\n",
    "\n",
    "print(len(filtered_train_df))\n",
    "len(filtered_val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432888/165425424.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_train_df['mbert_token_classes'] = filtered_train_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))\n",
      "/tmp/ipykernel_432888/165425424.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_val_df['mbert_token_classes'] = filtered_val_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))\n"
     ]
    }
   ],
   "source": [
    "def filter_labels(labels_str, valid_labels):\n",
    "    try:\n",
    "        if isinstance(labels_str, str):\n",
    "            labels = ast.literal_eval(labels_str)\n",
    "        elif isinstance(labels_str, list):\n",
    "            labels = labels_str\n",
    "        else:\n",
    "            return ['O'] * 128  # Assuming max length of 128\n",
    "\n",
    "        # Replace labels not in valid_labels with 'O'\n",
    "        return [label if label in valid_labels else 'O' for label in labels]\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing labels: {e}, value: {labels_str}\")\n",
    "        return ['O'] * 128  # Assuming max length of 128\n",
    "valid_labels = ['O', 'B-ACCOUNTNUM', 'I-ACCOUNTNUM', 'B-IDCARDNUM', 'I-IDCARDNUM']\n",
    "filtered_train_df['mbert_token_classes'] = filtered_train_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))\n",
    "filtered_val_df['mbert_token_classes'] = filtered_val_df['mbert_token_classes'].apply(lambda x: filter_labels(x, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 unique base labels (excluding O)\n",
      "Total number of labels after mapping: 3\n",
      "\n",
      "Label mapping:\n",
      "B-ACCOUNTNUM: 1\n",
      "B-IDCARDNUM: 2\n",
      "I-ACCOUNTNUM: 1\n",
      "I-IDCARDNUM: 2\n",
      "O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at iiiorg/piiranha-v1-detect-personal-information and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([18]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([18, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights of the model saved to pii_model/initial_weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 unique base labels (excluding O)\n",
      "Total number of labels after mapping: 3\n",
      "\n",
      "Label mapping:\n",
      "B-ACCOUNTNUM: 1\n",
      "B-IDCARDNUM: 2\n",
      "I-ACCOUNTNUM: 1\n",
      "I-IDCARDNUM: 2\n",
      "O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /teamspace/studios/this_studio/pii_model/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b16626e59c44389cded2567d7bbb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision_label_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall_label_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1_label_0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision_label_1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall_label_1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1_label_1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_precision_label_2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_recall_label_2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_f1_label_2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 0: checkpoint-epoch-00-loss-1.2656.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803a625a48ec4bc5911e97525cef66b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ec97f57c0e44ac9a453ff9f95ebe9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 0: checkpoint-epoch-00-loss-0.0242.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1de99432ace41f98d6ff60ddd24b965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 1: checkpoint-epoch-01-loss-0.0172.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57c30010f5d47c4bdc0866bdad91089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 2: checkpoint-epoch-02-loss-0.0197.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ffc6e0085a4953a22fb24a2789421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved checkpoint for epoch 3: checkpoint-epoch-03-loss-0.0177.ckpt\n",
      "\n",
      "Saved model configuration and weights for epoch 3.\n",
      "\n",
      "Training Summary:\n",
      "Total epochs completed: 1\n",
      "Best model saved at: /teamspace/studios/this_studio/pii_model/checkpoints/checkpoint-epoch=01-val_loss=0.0172.ckpt\n",
      "\n",
      "Final Best Metrics:\n",
      "\n",
      "Model saved to pii_model/final_model\n",
      "Available metric files:\n",
      "  - best_metrics.json\n",
      "  - metrics_epoch_0.json\n",
      "  - metrics_epoch_1.json\n",
      "  - metrics_epoch_2.json\n",
      "  - metrics_epoch_3.json\n",
      "\n",
      "Available checkpoints:\n",
      "  - checkpoint-epoch-00-loss-0.0242.ckpt\n",
      "  - checkpoint-epoch-00-loss-1.2656.ckpt\n",
      "  - checkpoint-epoch-01-loss-0.0172.ckpt\n",
      "  - checkpoint-epoch-02-loss-0.0197.ckpt\n",
      "  - checkpoint-epoch-03-loss-0.0177.ckpt\n",
      "  - checkpoint-epoch=01-val_loss=0.0172.ckpt\n",
      "  - checkpoint-epoch=02-val_loss=0.0197.ckpt\n",
      "  - checkpoint-epoch=03-val_loss=0.0177.ckpt\n",
      "  - last-v1.ckpt\n",
      "  - last-v2.ckpt\n",
      "  - last.ckpt\n"
     ]
    }
   ],
   "source": [
    "model, label_mapper = train_pii_model(filtered_train_df, filtered_val_df,batch_size=32, save_dir=\"pii_model\", max_epochs=10)\n",
    "\n",
    "list_saved_metrics() # Best metrics and best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "config = AutoConfig.from_pretrained(\"pii_model/checkpoints/model_epoch_01\")\n",
    "\n",
    "# Initialize the model with the config\n",
    "model = AutoModelForTokenClassification.from_config(config)\n",
    "\n",
    "# Load the safetensors weights\n",
    "state_dict = load_file(\"pii_model/checkpoints/model_epoch_01/model.safetensors\")\n",
    "\n",
    "# Load the state dict into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "\n",
    "# Load the label mapper if needed\n",
    "with open(\"pii_model/label_mapper.json\", 'r') as f:\n",
    "    label_mapper_data = json.load(f)\n",
    "\n",
    "label_mapper = LabelMapper()\n",
    "label_mapper.label_to_id = label_mapper_data['label_to_id']\n",
    "label_mapper.id_to_label = {int(k): v for k, v in label_mapper_data['id_to_label'].items()}\n",
    "label_mapper.num_labels = label_mapper_data['num_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 2    Budget Proposal    Proposal outlining the budget allocation for a specific project or department.\n",
      "Begrotingsaanvraag voor de marketing afdeling, specifiek project ID 389680211. Budget: 115,190.18 euro. Bevestiging via postcode 6718 en rekeningnummer 614170101. Adres: Quadruplex 90.\n",
      "\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-IDCARDNUM', 'I-IDCARDNUM', 'I-IDCARDNUM', 'I-IDCARDNUM', 'I-IDCARDNUM', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ACCOUNTNUM', 'I-ACCOUNTNUM', 'I-ACCOUNTNUM', 'I-ACCOUNTNUM', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Token-label alignment:\n",
      "[CLS]: O\n",
      "2: O\n",
      "Budget: O\n",
      "Pro: O\n",
      "##posal: O\n",
      "Pro: O\n",
      "##posal: O\n",
      "out: O\n",
      "##lini: O\n",
      "##ng: O\n",
      "the: O\n",
      "budget: O\n",
      "allo: O\n",
      "##cation: O\n",
      "for: O\n",
      "a: O\n",
      "specific: O\n",
      "project: O\n",
      "or: O\n",
      "department: O\n",
      ".: O\n",
      "Be: O\n",
      "##gro: O\n",
      "##tings: O\n",
      "##aan: O\n",
      "##vra: O\n",
      "##ag: O\n",
      "voor: O\n",
      "de: O\n",
      "marketing: O\n",
      "afdeling: O\n",
      ",: O\n",
      "sp: O\n",
      "##eci: O\n",
      "##fie: O\n",
      "##k: O\n",
      "project: O\n",
      "ID: B-IDCARDNUM\n",
      "389: I-IDCARDNUM\n",
      "##6: I-IDCARDNUM\n",
      "##80: I-IDCARDNUM\n",
      "##21: I-IDCARDNUM\n",
      "##1: O\n",
      ".: O\n",
      "Budget: O\n",
      ":: O\n",
      "115: O\n",
      ",: O\n",
      "190: O\n",
      ".: O\n",
      "18: O\n",
      "euro: O\n",
      ".: O\n",
      "Be: O\n",
      "##vesti: O\n",
      "##ging: O\n",
      "via: O\n",
      "post: O\n",
      "##code: O\n",
      "671: O\n",
      "##8: O\n",
      "en: O\n",
      "reke: O\n",
      "##ning: O\n",
      "##nummer: B-ACCOUNTNUM\n",
      "614: I-ACCOUNTNUM\n",
      "##17: I-ACCOUNTNUM\n",
      "##01: I-ACCOUNTNUM\n",
      "##01: O\n",
      ".: O\n",
      "Ad: O\n",
      "##res: O\n",
      ":: O\n",
      "Qua: O\n",
      "##dru: O\n",
      "##plex: O\n",
      "90: O\n",
      ".: O\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Get the text\n",
    "text = filtered_val_df.iloc[58].source_text\n",
    "\n",
    "\n",
    "# Tokenize with padding and truncation\n",
    "encoded_text = tokenizer(\n",
    "    text,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,  # or whatever max_length you used during training\n",
    "    return_tensors=\"pt\"  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Move inputs to the same device as model\n",
    "inputs = {\n",
    "    'input_ids': encoded_text['input_ids'].to(device),\n",
    "    'attention_mask': encoded_text['attention_mask'].to(device)\n",
    "}\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predictions\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Convert predictions to labels using label_mapper\n",
    "predicted_labels = label_mapper.decode(predictions[0].cpu().tolist())\n",
    "\n",
    "# Print results\n",
    "print(\"Original text:\", text)\n",
    "print(\"\\nPredicted labels:\", predicted_labels)\n",
    "\n",
    "# If you want to see the token-label alignment:\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text['input_ids'][0])\n",
    "print(\"\\nToken-label alignment:\")\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    if token != '[PAD]':  # Skip padding tokens\n",
    "        print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
