{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,AutoConfig\n",
    "import pytorch_lightning as pl\n",
    "import ast\n",
    "from torchmetrics import Precision, Recall, F1Score, Accuracy\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from typing import Optional, Dict, Any, List\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, DebertaV2TokenizerFast, BertTokenizerFast, AutoModelForTokenClassification\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "piiranha_tokenizer = DebertaV2TokenizerFast.from_pretrained(\"iiiorg/piiranha-v1-detect-personal-information\")\n",
    "piiranha_model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "piiranha_model.to(device)\n",
    "\n",
    "# Function to apply PII masking\n",
    "def mask_pii(text, predictions=None, model=piiranha_model, tokenizer=piiranha_tokenizer, aggregate_redaction=True):\n",
    "    model.to(device)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs.to(device)\n",
    "\n",
    "    if predictions == None:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    encoded_inputs = tokenizer.encode_plus(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "    offset_mapping = encoded_inputs['offset_mapping']\n",
    "\n",
    "    masked_text = list(text)\n",
    "    is_redacting = False\n",
    "    redaction_start = 0\n",
    "    current_pii_type = ''\n",
    "\n",
    "    for i, (start, end) in enumerate(offset_mapping):\n",
    "        if start == end:\n",
    "            continue\n",
    "\n",
    "        label = predictions[0][i].item()\n",
    "        if label != model.config.label2id['O']:\n",
    "            pii_type = model.config.id2label[label]\n",
    "            if not is_redacting:\n",
    "                is_redacting = True\n",
    "                redaction_start = start\n",
    "                current_pii_type = pii_type\n",
    "            elif not aggregate_redaction and pii_type != current_pii_type:\n",
    "                apply_redaction(masked_text, redaction_start, start, current_pii_type, aggregate_redaction)\n",
    "                redaction_start = start\n",
    "                current_pii_type = pii_type\n",
    "        else:\n",
    "            if is_redacting:\n",
    "                apply_redaction(masked_text, redaction_start, end, current_pii_type, aggregate_redaction)\n",
    "                is_redacting = False\n",
    "\n",
    "    if is_redacting:\n",
    "        apply_redaction(masked_text, redaction_start, len(masked_text), current_pii_type, aggregate_redaction)\n",
    "\n",
    "    return ''.join(masked_text)\n",
    "\n",
    "def apply_redaction(masked_text, start, end, pii_type, aggregate_redaction):\n",
    "    for j in range(start, end):\n",
    "        masked_text[j] = ''\n",
    "    if aggregate_redaction:\n",
    "        masked_text[start] = '[redacted]'\n",
    "    else:\n",
    "        masked_text[start] = f'[{pii_type}]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG TEXT\n",
      "<p>My child faozzsd379223 (DOB: May/58) will undergo treatment with Dr. faozzsd379223, office at Hill Road. Our ZIP code is 28170-6392. Consult policy M.UE.227995. Contact number: 0070.606.322.6244. Handle transactions with 6225427220412963. Queries? Email: faozzsd379223@outlook.com.</p>\n",
      "Aggregated redaction:\n",
      "<p>My child[I-USERNAME]DOB:[I-DATEOFBIRTH] undergo treatment with Dr.[I-USERNAME] office at[I-STREET] Our ZIP code is[I-ZIPCODE] Consult policy M.UE.227995. Contact number:[I-TELEPHONENUM] Handle transactions with 6225427220412963. Queries? Email:[I-EMAIL]p>\n"
     ]
    }
   ],
   "source": [
    "example_text=\"<p>My child faozzsd379223 (DOB: May/58) will undergo treatment with Dr. faozzsd379223, office at Hill Road. Our ZIP code is 28170-6392. Consult policy M.UE.227995. Contact number: 0070.606.322.6244. Handle transactions with 6225427220412963. Queries? Email: faozzsd379223@outlook.com.</p>\"\n",
    "print(\"OG TEXT\")\n",
    "print(example_text)\n",
    "print(\"Aggregated redaction:\")\n",
    "masked_example_aggregated = mask_pii(example_text, aggregate_redaction=False)\n",
    "print(masked_example_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "valid_df = pd.read_csv(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "\n",
    "input_col_name, output_col_name = 'source_text', 'mbert_token_classes'\n",
    "x_train, y_train = train_df[input_col_name].to_list(), train_df[output_col_name].apply(ast.literal_eval).to_list()\n",
    "x_valid, y_valid = valid_df[input_col_name].to_list(), valid_df[output_col_name].apply(ast.literal_eval).to_list()\n",
    "train_df['privacy_mask'] = train_df['privacy_mask'].apply(ast.literal_eval)\n",
    "valid_df['privacy_mask'] = valid_df['privacy_mask'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(label: str):\n",
    "    if label.startswith('B-') or label.startswith('I-'):\n",
    "        return label[2:]\n",
    "    else: return label\n",
    "\n",
    "def label2id(label, model):\n",
    "    if label.startswith('B-'):\n",
    "        label = 'I-' + label[2:]\n",
    "    return model.config.label2id[label]\n",
    "\n",
    "def id2label(id, model):\n",
    "    label = model.config.id2label[id]\n",
    "    return normalize_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = x_valid[27]\n",
    "labels = y_valid[27]\n",
    "s = valid_df.iloc[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniagent_model = AutoModelForTokenClassification.from_pretrained('model_epoch_03', )\n",
    "from safetensors.torch import load_file\n",
    "config = AutoConfig.from_pretrained('pii_model/checkpoints/best_model')\n",
    "miniagent_model = AutoModelForTokenClassification.from_config(config)\n",
    "state_dict = load_file('pii_model/checkpoints/best_model/model.safetensors')\n",
    "miniagent_model.load_state_dict(state_dict)\n",
    "\n",
    "miniagent_tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "miniagent_model.config.id2label = {0: 'O', 1: 'I-ACCOUNTNUM', 2: 'I-IDCARDNUM'}\n",
    "miniagent_model.config.label2id = {'O': 0, 'I-ACCOUNTNUM': 1, 'I-IDCARDNUM': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label_id': 2, 'label': 'IDCARDNUM', 'start': 16, 'end': 24, 'value': ' 6631488'}]\n"
     ]
    }
   ],
   "source": [
    "def make_privacy_mask(model, tokenizer, text, predictions = None):\n",
    "    model.to(device)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs.to(device)\n",
    "    # inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    if predictions == None:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    encoded_inputs = tokenizer.encode_plus(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "    offset_mapping = encoded_inputs['offset_mapping']\n",
    "    oid = label2id('O', model)\n",
    "    privacy_mask = []\n",
    "    current_pii = None\n",
    "    for id, (start, end) in zip(list(predictions[0].tolist()), offset_mapping):\n",
    "        if current_pii is not None and (id == oid or current_pii['label_id'] != id): \n",
    "            privacy_mask.append(current_pii)\n",
    "            current_pii = None\n",
    "        if id != oid and current_pii is None:\n",
    "            current_pii = {\n",
    "                'label_id': id,\n",
    "                'label': id2label(id, model),\n",
    "                'start': start+1,\n",
    "                'end': end,\n",
    "                'value': text[start:end]\n",
    "            }\n",
    "        elif id != oid and current_pii is not None:\n",
    "            current_pii['end'] = end\n",
    "            current_pii['value'] = text[current_pii['start']:end]\n",
    "    return privacy_mask\n",
    "\n",
    "# text = x_valid[27]\n",
    "# labels = y_valid[27]\n",
    "# s = valid_df.iloc[27]\n",
    "text = '<p>Validatie ID: 663148812, Sociale beveiliging: 862460623.</p><p>Vertrek via: Duplex 69, Schiedam, 156.</p>'\n",
    "make_privacy_mask(piiranha_model, piiranha_tokenizer, text)\n",
    "mg_pm = make_privacy_mask(miniagent_model, miniagent_tokenizer, text)\n",
    "print(mg_pm)\n",
    "# print(s.privacy_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_set = [(yv, xv) for yv, xv in zip(y_valid, x_valid) if 'I-ACCOUNTNUM' in yv or 'I-IDCARDNUM' in yv]\n",
    "# yv, xv = zip(*valid_set)\n",
    "\n",
    "yv, xv = y_valid, x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_labels = {'FP':{}, 'FN':{}, 'TP':{}}\n",
    "true_positives = {}\n",
    "def score(predicted_mask, mask):\n",
    "    equals = lambda pii, pred: \\\n",
    "        pred['label'] == pii['label'] and \\\n",
    "        pred['start'] == pii['start'] and \\\n",
    "        pred['end'] == pii['end']\n",
    "    for pii in mask:\n",
    "        if any(equals(pii, pred) for pred in predicted_mask):\n",
    "            label = pii['label']\n",
    "            if label not in wrong_labels['TP']:\n",
    "                wrong_labels['TP'][label] = 1\n",
    "            else:\n",
    "                wrong_labels['TP'][label] += 1\n",
    "            if label not in true_positives:\n",
    "                true_positives[label] = [pii['value']]\n",
    "            elif len(true_positives[label]) < 50:\n",
    "                true_positives[label].append(pii['value'])\n",
    "        if all(not equals(pii, pred) for pred in predicted_mask):\n",
    "            label = pii['label']\n",
    "            if label not in wrong_labels['FN']:\n",
    "                wrong_labels['FN'][label] = 1\n",
    "            else:\n",
    "                wrong_labels['FN'][label] += 1\n",
    "    for pred in predicted_mask:\n",
    "        if all(not equals(pii, pred) for pii in mask):\n",
    "            label = pred['label']\n",
    "            if label not in wrong_labels['FP']:\n",
    "                wrong_labels['FP'][label] = 1\n",
    "            else:\n",
    "                wrong_labels['FP'][label] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_privacy_mask(model, tokenizer, texts):\n",
    "    model.to(device)\n",
    "    try:\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        inputs.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        predictionss = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        privacy_masks = []\n",
    "        for (predictions, text) in zip(predictionss, texts):\n",
    "            encoded_inputs = tokenizer.encode_plus(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "            offset_mapping = encoded_inputs['offset_mapping']\n",
    "            oid = label2id('O', model)\n",
    "            privacy_mask = []\n",
    "            current_pii = None\n",
    "            for id, (start, end) in zip(list(predictions.tolist()), offset_mapping):\n",
    "                if current_pii is not None and (id == oid or current_pii['label_id'] != id): \n",
    "                    privacy_mask.append(current_pii)\n",
    "                    current_pii = None\n",
    "                if id != oid and current_pii is None:\n",
    "                    current_pii = {\n",
    "                        'label_id': id,\n",
    "                        'label': id2label(id, model),\n",
    "                        'start': start+1,\n",
    "                        'end': end,\n",
    "                        'value': text[start:end]\n",
    "                    }\n",
    "                elif id != oid and current_pii is not None:\n",
    "                    current_pii['end'] = end\n",
    "                    current_pii['value'] = text[current_pii['start']:end]\n",
    "            privacy_masks.append(privacy_mask)\n",
    "        return privacy_masks\n",
    "    except: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [07:15<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FP': {'GIVENNAME': 20962, 'SURNAME': 9277, 'EMAIL': 7637, 'DATEOFBIRTH': 3326, 'STREET': 3603, 'BUILDINGNUM': 3462, 'TELEPHONENUM': 4609, 'USERNAME': 11474, 'SOCIALNUM': 3131, 'CITY': 8136, 'ZIPCODE': 3327, 'IDCARDNUM': 4206, 'DRIVERLICENSENUM': 2256, 'CREDITCARDNUMBER': 2299, 'PASSWORD': 2567, 'ACCOUNTNUM': 3749, 'TAXNUM': 2211}, 'FN': {'GIVENNAME': 13843, 'USERNAME': 8317, 'TELEPHONENUM': 6151, 'EMAIL': 6834, 'STREET': 4163, 'BUILDINGNUM': 4467, 'IDCARDNUM': 4666, 'SURNAME': 8124, 'ACCOUNTNUM': 3874, 'CITY': 8124, 'DRIVERLICENSENUM': 2478, 'TAXNUM': 3675, 'SOCIALNUM': 2678, 'DATEOFBIRTH': 2184, 'CREDITCARDNUMBER': 3177, 'ZIPCODE': 3570, 'PASSWORD': 2480}, 'TP': {'GIVENNAME': 157, 'USERNAME': 83, 'TELEPHONENUM': 49, 'EMAIL': 66, 'STREET': 37, 'BUILDINGNUM': 33, 'IDCARDNUM': 34, 'SURNAME': 76, 'ACCOUNTNUM': 26, 'CITY': 76, 'DRIVERLICENSENUM': 22, 'TAXNUM': 25, 'SOCIALNUM': 22, 'CREDITCARDNUMBER': 23, 'ZIPCODE': 30, 'PASSWORD': 20, 'DATEOFBIRTH': 16}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "wrong_labels = {'FP':{}, 'FN':{}, 'TP':{}}\n",
    "true_positives = {}\n",
    "\n",
    "BATCH = 100\n",
    "for i in tqdm(range(0, len(xv), BATCH)):\n",
    "    s = valid_df.iloc[i]\n",
    "    text = xv[i:min(i+BATCH,len(xv)-1)]\n",
    "    pm = batch_privacy_mask(piiranha_model, piiranha_tokenizer, text)\n",
    "    for pm, text in zip(pm, text):\n",
    "        score(pm, s.privacy_mask)\n",
    "print(wrong_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:       <p>Validatie ID: 663148812, Sociale beveiliging: 862460623.</p><p>Vertrek via: Duplex 69, Schiedam, 156.</p>\n",
      "Ground truth:        <p>Klant [USERNAME_1] uit [CITY_1] bindt zich aan deze gezondheidsverzekering. Gebruik [PASSWORD_1] voor toegang tot uw polis. Premies worden van rekening [ACCOUNTNUM_1] bij bank National Australia Bank afgeschreven. Krachtsmidden zijn [CREDITCARDNUMBER_1] en [CREDITCARDEXPIRYCREDITCARDCVV_1]. PIN voor verificatie: [PIN_1].</p>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked by piiranha:  <p>Validatie ID:[I-IDCARDNUM] Sociale beveiliging:[I-SOCIALNUM]p><p>Vertrek via: Duplex 69,[I-CITY][I-BUILDINGNUM]p>\n",
      "Masked by miniagent: <p>Validatie ID[I-IDCARDNUM], Sociale beveiliging: 862460623.</p><p>Vertrek via: Duplex 69, Schiedam, 156.</p>\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:       \" + text)\n",
    "print(\"Ground truth:        \" + s.masked_text)\n",
    "piiranha_model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "masked = mask_pii(text, model=piiranha_model, tokenizer=piiranha_tokenizer, aggregate_redaction=False)\n",
    "print(\"Masked by piiranha:  \" + masked)\n",
    "masked = mask_pii(text, model=miniagent_model, tokenizer=miniagent_tokenizer, aggregate_redaction=False)\n",
    "print(\"Masked by miniagent: \" + masked)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
